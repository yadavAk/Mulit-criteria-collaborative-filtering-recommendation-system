# -*- coding: utf-8 -*-
"""RecommendationSystem.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/12uqir2gFQ8pBp9-U5QTI3wrGJLElKe5O
"""
	
#import os
#os.chdir('/content/drive/My Drive/Code/FinalProject')

import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.text import one_hot

from tensorflow.keras.layers import Embedding, Input, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras import initializers, optimizers

initializer = initializers.RandomNormal(mean = 0.0,stddev = 0.05)

def fetchData(filename):
	df = pd.read_csv(filename)
	sub_df = df[df.groupby('authors').authors.transform('count')>2].copy() # preProcess Data(Remove row with authors count <=3 )
	sub_df.drop_duplicates(inplace = True)
	sub_df.reset_index(inplace = True,drop = True)
	sub_df.to_csv('sub_data.csv')
	return sub_df

def divideData(df,hotels_dic,authors_dic):
	authorId_Evec = []
	movieId_Evec = []
	criteria_rates = []
	overall_rates = []
	for index in range(len(df)):	
		lst = df.loc[index]
		lst = (lst.to_numpy().tolist())
		authorId_Evec.append(authors_dic[lst[0]])
		movieId_Evec.append(hotels_dic[lst[1]])
		overall_rates.append(lst[2])
		arr = lst[3:10]
		for n, i in enumerate(arr):
			if i == -1:
				arr[n] = lst[2]
		criteria_rates.append(arr)
	
	m = np.mean(criteria_rates)
	s = np.std(criteria_rates)
	criteria_rates = np.subtract(criteria_rates,m)
	criteria_rates = np.divide(criteria_rates,s)
	
	return authorId_Evec, movieId_Evec, criteria_rates, overall_rates
	

def embedding_layer(dim,voc_size):
	model = Sequential()
	model.add(Embedding(voc_size,dim,input_length=1))
	model.compile('adam','mse')
	return model
	


def model_criteria(input_dim):
	model = Sequential()
	model.add(Dense(32,activation = 'relu',kernel_initializer = initializer ,input_shape = (input_dim,)))
	model.add(Dense(16,activation = 'relu',kernel_initializer = initializer))
	model.add(Dense(8,activation = 'relu',kernel_initializer = initializer))
	model.add(Dense(7,activation = 'relu',kernel_initializer = initializer))
	opt = optimizers.Adam(learning_rate=0.001)
	model.compile(optimizer=opt, loss = 'mse',metrics=['mae'])
	return model

def model_overall_rate(input_dim):
	model = Sequential()
	model.add(Dense(64,activation = 'relu',kernel_initializer = initializer, input_shape = (input_dim,)))
	model.add(Dense(32,activation = 'relu', kernel_initializer = initializer))
	model.add(Dense(16,activation = 'relu', kernel_initializer = initializer))
	model.add(Dense(8,activation = 'relu', kernel_initializer = initializer))
	model.add(Dense(1,activation = 'relu', kernel_initializer = initializer))
	opt = optimizers.Adam(learning_rate = 0.001)
	model.compile(optimizer=opt,loss = 'mse',metrics=['mae'])
	return model

def findMap(model,keys,onehot_rep):
	dic = {}
	i = 0
	for value in onehot_rep:
		vec = model.predict(value)
		dic[keys[i]] = vec[0][0]
		if i%50 == 0:
			print(i)
		i += 1
	return dic
	

df = fetchData('data.csv')

unique_authors = df.authors.unique()
unique_hotels = df.hotels.unique()

authors_voc_size = len(unique_authors)
hotels_voc_size = len(unique_hotels)

"""**OneHot Representation**"""

authors_onehot_rep = [one_hot(str(word)+'dum',authors_voc_size) for word in unique_authors]
hotels_onehot_rep = [one_hot(str(word)+'dum',hotels_voc_size) for word in unique_hotels]

"""**Word Embedding Representation**"""

# 64 Dimensions
dim = 64

model_author = embedding_layer(dim,authors_voc_size)
model_hotel = embedding_layer(dim,hotels_voc_size)

#model_author.summary()
#model_hotel.summary()

hotels_dic = findMap(model_hotel,unique_hotels,hotels_onehot_rep)
authors_dic = findMap(model_author,unique_authors,authors_onehot_rep)
# Save
np.save('hotels_dic3.npy', hotels_dic) 
np.save('authors_dic3.npy', authors_dic) 

# Load
hotels_dic = np.load('hotels_dic3.npy',allow_pickle='TRUE').item()
authors_dic = np.load('authors_dic3.npy',allow_pickle='TRUE').item()

authorId_Evec, movieId_Evec, criteria_rates, overall_rates = divideData(df,hotels_dic,authors_dic) #Uncomment
concat_vec_id = np.add(authorId_Evec,movieId_Evec)


""" Execute Models """

criteria_model = model_criteria(dim)
overall_rate_model = model_overall_rate(7)
#print(criteria_model.summary())
#print(overall_rate_model.summary())

history_criteria = criteria_model.fit(np.asarray(concat_vec_id), np.asarray(criteria_rates), batch_size = 512, epochs = 20,validation_split = 0.2) #Uncomment
print('overall Model --------------------------------------------------')
history_overall_rate = overall_rate_model.fit(np.asarray(criteria_rates), np.asarray(overall_rates), batch_size = 512, epochs = 20,validation_split = 0.2) #Uncomment


